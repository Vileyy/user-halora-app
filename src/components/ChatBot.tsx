import React, { useState, useEffect, useRef, useMemo } from "react";
import {
  View,
  Text,
  TextInput,
  TouchableOpacity,
  FlatList,
  StyleSheet,
  KeyboardAvoidingView,
  Platform,
  Animated,
  ActivityIndicator,
  Alert,
  Keyboard,
  Image,
} from "react-native";
import { Ionicons } from "@expo/vector-icons";
import { aiService } from "../services/aiService";
import { speechService } from "../services/speechService";
import { ChatMessage, UserProfile } from "../types/ai";

interface ChatBotProps {
  userProfile?: UserProfile;
  onClose: () => void;
  onProductRecommend?: (productId: string) => void;
  availableProducts?: any[];
}

const ChatBot: React.FC<ChatBotProps> = ({
  userProfile,
  onClose,
  onProductRecommend,
  availableProducts = [],
}) => {
  const [messages, setMessages] = useState<ChatMessage[]>([]);
  const [inputText, setInputText] = useState("");
  const [isTyping, setIsTyping] = useState(false);
  const [isVisible, setIsVisible] = useState(false);
  const [keyboardHeight, setKeyboardHeight] = useState(0);
  const [isRecording, setIsRecording] = useState(false);
  const [recording, setRecording] = useState<any>(null);
  const [isProcessingVoice, setIsProcessingVoice] = useState(false);

  const flatListRef = useRef<FlatList>(null);
  const slideAnim = useRef(new Animated.Value(300)).current;
  const fadeAnim = useRef(new Animated.Value(0)).current;
  const recordingAnim = useRef(new Animated.Value(1)).current;

  // Helper function to get valid image URL
  const getValidImageUrl = (imageUrl: string | null | undefined): string => {
    if (
      imageUrl &&
      typeof imageUrl === "string" &&
      imageUrl !== "null" &&
      imageUrl.trim() !== ""
    ) {
      return imageUrl;
    }
    return "https://via.placeholder.com/60x60/FF99CC/FFFFFF?text=SP";
  };

  // Smart suggested questions based on available products and user profile
  const quickReplies = useMemo(() => {
    return generateSmartSuggestedQuestions(availableProducts, userProfile);
  }, [availableProducts, userProfile]);

  // Generate smart suggested questions
  function generateSmartSuggestedQuestions(
    products: any[],
    profile?: UserProfile
  ): string[] {
    const suggestions: string[] = [];

    // Analyze available products to create context-aware suggestions
    if (products && products.length > 0) {
      const categories = new Set<string>();
      const keywords = new Set<string>();

      products.slice(0, 20).forEach((product) => {
        if (product.category) categories.add(product.category.toLowerCase());
        if (product.name) {
          const name = product.name.toLowerCase();
          if (name.includes("serum")) keywords.add("serum");
          if (name.includes("toner")) keywords.add("toner");
          if (name.includes("kem") || name.includes("cream"))
            keywords.add("kem d∆∞·ª°ng");
          if (name.includes("t·∫©y trang") || name.includes("cleanser"))
            keywords.add("t·∫©y trang");
          if (name.includes("ch·ªëng n·∫Øng") || name.includes("sunscreen"))
            keywords.add("ch·ªëng n·∫Øng");
          if (name.includes("m·ª•n") || name.includes("acne"))
            keywords.add("m·ª•n");
        }
      });

      // Generate suggestions based on available products
      if (keywords.has("serum")) {
        suggestions.push("Serum n√†o ph√π h·ª£p v·ªõi da c·ªßa t√¥i?");
      }
      if (keywords.has("t·∫©y trang")) {
        suggestions.push("C√°ch ch·ªçn s·∫£n ph·∫©m t·∫©y trang ph√π h·ª£p?");
      }
      if (keywords.has("kem d∆∞·ª°ng")) {
        suggestions.push("Kem d∆∞·ª°ng ·∫©m n√†o t·ªët?");
      }
      if (keywords.has("ch·ªëng n·∫Øng")) {
        suggestions.push("Kem ch·ªëng n·∫Øng n√†o ph√π h·ª£p?");
      }
      if (keywords.has("m·ª•n")) {
        suggestions.push("S·∫£n ph·∫©m tr·ªã m·ª•n hi·ªáu qu·∫£?");
      }
    }

    // Add profile-based suggestions
    if (profile?.skinType) {
      suggestions.push(`Routine chƒÉm s√≥c da ${profile.skinType} nh∆∞ th·∫ø n√†o?`);
    } else {
      suggestions.push("T√¥i mu·ªën t∆∞ v·∫•n v·ªÅ skincare");
    }

    if (profile?.concerns && profile.concerns.length > 0) {
      const mainConcern = profile.concerns[0];
      suggestions.push(`S·∫£n ph·∫©m n√†o gi√∫p ${mainConcern}?`);
    } else {
      suggestions.push("S·∫£n ph·∫©m n√†o ph√π h·ª£p v·ªõi da c·ªßa t√¥i?");
    }

    // Fill remaining slots with general suggestions
    const defaultSuggestions = [
      "C√°ch chƒÉm s√≥c da bu·ªïi s√°ng",
      "Routine skincare t·ªëi thi·ªÉu",
    ];

    // Remove duplicates and limit to 5
    const uniqueSuggestions = Array.from(
      new Set([...suggestions, ...defaultSuggestions])
    ).slice(0, 5);

    return uniqueSuggestions.length > 0
      ? uniqueSuggestions
      : [
          "T√¥i mu·ªën t∆∞ v·∫•n v·ªÅ skincare",
          "S·∫£n ph·∫©m n√†o ph√π h·ª£p v·ªõi da d·∫ßu?",
          "C√°ch chƒÉm s√≥c da kh√¥?",
          "Routine chƒÉm s√≥c da bu·ªïi s√°ng",
          "S·∫£n ph·∫©m tr·ªã m·ª•n hi·ªáu qu·∫£",
        ];
  }

  useEffect(() => {
    setIsVisible(true);

    Animated.parallel([
      Animated.timing(slideAnim, {
        toValue: 0,
        duration: 300,
        useNativeDriver: true,
      }),
      Animated.timing(fadeAnim, {
        toValue: 1,
        duration: 300,
        useNativeDriver: true,
      }),
    ]).start();

    // Message welcome
    const welcomeMessage: ChatMessage = {
      id: "welcome",
      text: `Xin ch√†o! üëã T√¥i l√† tr·ª£ l√Ω AI chuy√™n t∆∞ v·∫•n m·ªπ ph·∫©m c·ªßa Halora. T√¥i c√≥ th·ªÉ gi√∫p b·∫°n:

üåü T∆∞ v·∫•n s·∫£n ph·∫©m ph√π h·ª£p v·ªõi l√†n da
üíÑ H∆∞·ªõng d·∫´n routine chƒÉm s√≥c da
üîç T√¨m ki·∫øm s·∫£n ph·∫©m theo nhu c·∫ßu
üí° Gi·∫£i ƒë√°p c√°c th·∫Øc m·∫Øc v·ªÅ skincare

‚úçÔ∏è **C√°ch s·ª≠ d·ª•ng:**
- G√µ tin nh·∫Øn ƒë·ªÉ chat b√¨nh th∆∞·ªùng
- Nh·∫•n n√∫t üé§ ƒë·ªÉ th·ª≠ voice input (demo mode)

üé§ **Voice Demo:** Sau khi "ghi √¢m", b·∫°n s·∫Ω th·∫•y menu ch·ªçn n·ªôi dung ho·∫∑c nh·∫≠p t·ª± do.

B·∫°n c·∫ßn t∆∞ v·∫•n g√¨ h√¥m nay?`,
      isUser: false,
      timestamp: new Date(),
    };

    setMessages([welcomeMessage]);

    // Keyboard event listeners
    const keyboardDidShowListener = Keyboard.addListener(
      "keyboardDidShow",
      (e) => {
        setKeyboardHeight(e.endCoordinates.height);
        // Auto scroll when keyboard appears
        setTimeout(() => scrollToBottom(), 100);
      }
    );

    const keyboardDidHideListener = Keyboard.addListener(
      "keyboardDidHide",
      () => {
        setKeyboardHeight(0);
      }
    );

    return () => {
      keyboardDidShowListener.remove();
      keyboardDidHideListener.remove();
    };
  }, []);

  const scrollToBottom = () => {
    setTimeout(() => {
      flatListRef.current?.scrollToEnd({ animated: true });
    }, 100);
  };

  const handleInputFocus = () => {
    // Auto scroll khi focus v√†o input
    setTimeout(() => scrollToBottom(), 150);
  };

  const handleSendMessage = async (text?: string) => {
    const messageText = text || inputText.trim();
    if (!messageText) return;

    const userMessage: ChatMessage = {
      id: Date.now().toString(),
      text: messageText,
      isUser: true,
      timestamp: new Date(),
    };

    setMessages((prev) => [...prev, userMessage]);
    setInputText("");
    setIsTyping(true);
    scrollToBottom();

    try {
      // Call AI service to get response
      const response = await aiService.getCosmeticAdvice(
        messageText,
        {
          skinType: userProfile?.skinType,
          age: userProfile?.age,
          concerns: userProfile?.concerns || [],
          currentProducts: userProfile?.currentProducts || [],
        },
        availableProducts
      );

      // Animation typing effect
      await new Promise((resolve) => setTimeout(resolve, 1500));

      const botMessage: ChatMessage = {
        id: Date.now().toString() + "_bot",
        text: response.advice,
        isUser: false,
        timestamp: new Date(),
      };

      setMessages((prev) => [...prev, botMessage]);
      if (
        response.recommendedProducts &&
        response.recommendedProducts.length > 0
      ) {
        const productMessage: ChatMessage = {
          id: Date.now().toString() + "_products",
          text: `üí° T√¥i t√¨m th·∫•y nh·ªØng s·∫£n ph·∫©m ph√π h·ª£p trong c·ª≠a h√†ng:`,
          isUser: false,
          timestamp: new Date(),
          recommendedProducts: response.recommendedProducts,
        };

        setTimeout(() => {
          setMessages((prev) => [...prev, productMessage]);
          scrollToBottom();
        }, 500);
      }
    } catch (error) {
      console.error("ChatBot Error:", error);

      const errorMessage: ChatMessage = {
        id: Date.now().toString() + "_error",
        text: "Xin l·ªói, t√¥i ƒëang g·∫∑p m·ªôt ch√∫t v·∫•n ƒë·ªÅ k·ªπ thu·∫≠t. B·∫°n c√≥ th·ªÉ th·ª≠ l·∫°i sau ho·∫∑c li√™n h·ªá v·ªõi ƒë·ªôi ng≈© t∆∞ v·∫•n vi√™n c·ªßa ch√∫ng t√¥i.",
        isUser: false,
        timestamp: new Date(),
      };

      setMessages((prev) => [...prev, errorMessage]);
    } finally {
      setIsTyping(false);
      scrollToBottom();
    }
  };

  const handleQuickReply = (reply: string) => {
    // Simply call handleSendMessage like the original behavior
    // This will show user message first, then typing indicator, then AI response with products
    handleSendMessage(reply);
  };

  // Voice Recording Functions
  const startRecording = async () => {
    try {
      // Request permissions
      const hasPermission = await speechService.requestPermissions();
      if (!hasPermission) {
        Alert.alert(
          "Quy·ªÅn truy c·∫≠p microphone",
          "·ª®ng d·ª•ng c·∫ßn quy·ªÅn truy c·∫≠p microphone ƒë·ªÉ ghi √¢m tin nh·∫Øn voice.",
          [{ text: "OK" }]
        );
        return;
      }

      // Start recording
      const newRecording = await speechService.startRecording();

      setRecording(newRecording);
      setIsRecording(true);

      // Start recording animation
      Animated.loop(
        Animated.sequence([
          Animated.timing(recordingAnim, {
            toValue: 0.3,
            duration: 500,
            useNativeDriver: true,
          }),
          Animated.timing(recordingAnim, {
            toValue: 1,
            duration: 500,
            useNativeDriver: true,
          }),
        ])
      ).start();
    } catch (error) {
      console.error("Failed to start recording:", error);
      Alert.alert("L·ªói", "Kh√¥ng th·ªÉ b·∫Øt ƒë·∫ßu ghi √¢m. Vui l√≤ng th·ª≠ l·∫°i.");
    }
  };

  const stopRecording = async () => {
    if (!recording) return;

    try {
      setIsRecording(false);
      setIsProcessingVoice(true);

      // Stop recording animation
      recordingAnim.stopAnimation();
      recordingAnim.setValue(1);

      const uri = await speechService.stopRecording(recording);

      if (uri) {
        // Process the audio file with speech-to-text
        await processVoiceMessage(uri);
      }

      setRecording(null);
    } catch (error) {
      console.error("Failed to stop recording:", error);
      Alert.alert("L·ªói", "Kh√¥ng th·ªÉ ho√†n th√†nh ghi √¢m. Vui l√≤ng th·ª≠ l·∫°i.");
    } finally {
      setIsProcessingVoice(false);
    }
  };

  const processVoiceMessage = async (audioUri: string) => {
    try {
      // Convert speech to text using speech service
      const transcribedText = await speechService.speechToText(audioUri);

      if (transcribedText && transcribedText.trim()) {
        // Auto-send the transcribed text as message
        await handleSendMessage(transcribedText);
      } else {
        Alert.alert(
          "Kh√¥ng th·ªÉ nh·∫≠n di·ªán gi·ªçng n√≥i",
          "Vui l√≤ng th·ª≠ n√≥i r√µ h∆°n ho·∫∑c nh·∫≠p tin nh·∫Øn text.",
          [
            {
              text: "Nh·∫≠p tin nh·∫Øn",
              onPress: () => {
                // Focus on text input
                setTimeout(() => {
                  // You can add auto-focus logic here
                }, 100);
              },
            },
            { text: "Th·ª≠ l·∫°i", onPress: startRecording },
          ]
        );
      }
    } catch (error) {
      console.error("Failed to process voice message:", error);
      Alert.alert(
        "L·ªói x·ª≠ l√Ω gi·ªçng n√≥i",
        "Kh√¥ng th·ªÉ chuy·ªÉn ƒë·ªïi gi·ªçng n√≥i th√†nh vƒÉn b·∫£n. Vui l√≤ng th·ª≠ l·∫°i ho·∫∑c nh·∫≠p tin nh·∫Øn text.",
        [
          {
            text: "Nh·∫≠p tin nh·∫Øn",
            style: "default",
          },
          {
            text: "Th·ª≠ l·∫°i",
            onPress: startRecording,
            style: "default",
          },
        ]
      );
    }
  };

  const handleVoicePress = () => {
    if (isRecording) {
      stopRecording();
    } else {
      startRecording();
    }
  };

  const handleClose = () => {
    Animated.parallel([
      Animated.timing(slideAnim, {
        toValue: 300,
        duration: 250,
        useNativeDriver: true,
      }),
      Animated.timing(fadeAnim, {
        toValue: 0,
        duration: 250,
        useNativeDriver: true,
      }),
    ]).start(() => {
      setIsVisible(false);
      onClose();
    });
  };

  const renderMessage = ({ item }: { item: ChatMessage }) => (
    <View
      style={[
        styles.messageContainer,
        item.isUser ? styles.userMessageContainer : styles.botMessageContainer,
      ]}
    >
      {!item.isUser && (
        <View style={styles.botAvatar}>
          <Ionicons name="sparkles" size={16} color="#FF99CC" />
        </View>
      )}

      <View
        style={[
          styles.messageBubble,
          item.isUser ? styles.userMessage : styles.botMessage,
        ]}
      >
        <Text
          style={[
            styles.messageText,
            item.isUser ? styles.userMessageText : styles.botMessageText,
          ]}
        >
          {item.text}
        </Text>

        {/* Display product recommendations */}
        {item.recommendedProducts && item.recommendedProducts.length > 0 && (
          <View style={styles.productsContainer}>
            {item.recommendedProducts.map((product, index) => (
              <TouchableOpacity
                key={`${product.id}_${index}`}
                style={styles.productCard}
                onPress={() => onProductRecommend?.(product.id)}
              >
                <View style={styles.productImageContainer}>
                  <Image
                    source={{
                      uri: getValidImageUrl(product.image),
                    }}
                    style={styles.productImage}
                    defaultSource={require("../assets/image/halora-icon.png")}
                    resizeMode="cover"
                    onError={() =>
                      console.log("Image failed to load:", product.image)
                    }
                  />
                </View>
                <View style={styles.productInfo}>
                  <Text style={styles.productName} numberOfLines={2}>
                    {product.name}
                  </Text>
                  <Text style={styles.productReason} numberOfLines={2}>
                    {product.reason}
                  </Text>
                </View>
                <View style={styles.productAction}>
                  <Ionicons name="chevron-forward" size={16} color="#FF99CC" />
                </View>
              </TouchableOpacity>
            ))}
          </View>
        )}

        <Text style={styles.timestamp}>
          {item.timestamp.toLocaleTimeString("vi-VN", {
            hour: "2-digit",
            minute: "2-digit",
          })}
        </Text>
      </View>
    </View>
  );

  const renderTypingIndicator = () => (
    <View style={styles.typingContainer}>
      <View style={styles.botAvatar}>
        <Ionicons name="sparkles" size={16} color="#FF99CC" />
      </View>
      <View style={styles.typingBubble}>
        <ActivityIndicator size="small" color="#666" />
        <Text style={styles.typingText}>ƒêang so·∫°n tin...</Text>
      </View>
    </View>
  );

  const renderRecordingIndicator = () => (
    <View style={styles.recordingContainer}>
      <View style={styles.recordingIndicator}>
        <Animated.View
          style={[styles.recordingDot, { opacity: recordingAnim }]}
        />
        <Text style={styles.recordingText}>
          üé§ ƒêang ghi √¢m (Demo)... Nh·∫•n n√∫t ƒë·ªè ƒë·ªÉ d·ª´ng
        </Text>
      </View>
    </View>
  );

  const renderQuickReplies = () => (
    <View style={styles.quickRepliesContainer}>
      <Text style={styles.quickRepliesTitle}>G·ª£i √Ω c√¢u h·ªèi:</Text>
      <FlatList
        data={quickReplies}
        renderItem={({ item }) => (
          <TouchableOpacity
            style={styles.quickReplyButton}
            onPress={() => handleQuickReply(item)}
          >
            <Text style={styles.quickReplyText}>{item}</Text>
          </TouchableOpacity>
        )}
        keyExtractor={(item, index) => index.toString()}
        horizontal
        showsHorizontalScrollIndicator={false}
        contentContainerStyle={styles.quickRepliesList}
      />
    </View>
  );

  if (!isVisible) return null;

  return (
    <Animated.View
      style={[
        styles.container,
        {
          opacity: fadeAnim,
          transform: [{ translateY: slideAnim }],
          paddingBottom: keyboardHeight > 0 ? keyboardHeight : 0,
        },
      ]}
    >
      <KeyboardAvoidingView
        style={styles.keyboardView}
        behavior={Platform.OS === "ios" ? "padding" : "height"}
        keyboardVerticalOffset={Platform.OS === "ios" ? 0 : 20}
      >
        {/* Header */}
        <View style={styles.header}>
          <View style={styles.headerLeft}>
            <View style={styles.aiIndicator}>
              <Ionicons name="sparkles" size={20} color="#fff" />
            </View>
            <View>
              <Text style={styles.headerTitle}>Halora AI Assistant</Text>
              <Text style={styles.headerSubtitle}>
                {isRecording
                  ? "üé§ ƒêang ghi √¢m..."
                  : isProcessingVoice
                  ? "üîÑ ƒêang x·ª≠ l√Ω voice..."
                  : isTyping
                  ? "‚úçÔ∏è ƒêang tr·∫£ l·ªùi..."
                  : "üí¨ T∆∞ v·∫•n vi√™n AI (Voice Demo)"}
              </Text>
            </View>
          </View>

          <TouchableOpacity onPress={handleClose} style={styles.closeButton}>
            <Ionicons name="close" size={24} color="#333" />
          </TouchableOpacity>
        </View>

        {/* Messages */}
        <FlatList
          ref={flatListRef}
          data={messages}
          renderItem={renderMessage}
          keyExtractor={(item) => item.id}
          style={styles.messagesList}
          contentContainerStyle={styles.messagesContainer}
          showsVerticalScrollIndicator={false}
        />

        {/* Typing Indicator */}
        {isTyping && renderTypingIndicator()}

        {/* Recording Indicator */}
        {isRecording && renderRecordingIndicator()}

        {/* Quick Replies */}
        {messages.length <= 1 && renderQuickReplies()}

        {/* Input */}
        <View style={styles.inputContainer}>
          <TextInput
            style={styles.textInput}
            value={inputText}
            onChangeText={setInputText}
            onFocus={handleInputFocus}
            placeholder="Nh·∫≠p c√¢u h·ªèi c·ªßa b·∫°n ho·∫∑c nh·∫•n mic ƒë·ªÉ ghi √¢m..."
            placeholderTextColor="#999"
            multiline
            maxLength={500}
            editable={!isRecording && !isProcessingVoice}
          />

          {/* Voice Recording Button */}
          <TouchableOpacity
            style={[
              styles.voiceButton,
              isRecording && styles.voiceButtonRecording,
              isProcessingVoice && styles.voiceButtonProcessing,
            ]}
            onPress={handleVoicePress}
            disabled={isTyping || isProcessingVoice}
          >
            {isProcessingVoice ? (
              <ActivityIndicator size="small" color="#fff" />
            ) : (
              <Ionicons
                name={isRecording ? "stop" : "mic"}
                size={20}
                color="#fff"
              />
            )}
          </TouchableOpacity>

          <TouchableOpacity
            style={[
              styles.sendButton,
              !inputText.trim() && styles.sendButtonDisabled,
            ]}
            onPress={() => handleSendMessage()}
            disabled={
              !inputText.trim() || isTyping || isRecording || isProcessingVoice
            }
          >
            <Ionicons
              name="send"
              size={20}
              color={inputText.trim() ? "#fff" : "#ccc"}
            />
          </TouchableOpacity>
        </View>
      </KeyboardAvoidingView>
    </Animated.View>
  );
};

const styles = StyleSheet.create({
  container: {
    position: "absolute",
    top: 0,
    left: 0,
    right: 0,
    bottom: 0,
    backgroundColor: "rgba(0,0,0,0.5)",
    zIndex: 1000,
  },
  keyboardView: {
    flex: 1,
    marginTop: 50,
    backgroundColor: "#fff",
    borderTopLeftRadius: 20,
    borderTopRightRadius: 20,
  },
  header: {
    flexDirection: "row",
    alignItems: "center",
    justifyContent: "space-between",
    padding: 16,
    borderBottomWidth: 1,
    borderBottomColor: "#eee",
    backgroundColor: "#fff",
    borderTopLeftRadius: 20,
    borderTopRightRadius: 20,
  },
  headerLeft: {
    flexDirection: "row",
    alignItems: "center",
  },
  aiIndicator: {
    width: 40,
    height: 40,
    borderRadius: 20,
    backgroundColor: "#FF99CC",
    alignItems: "center",
    justifyContent: "center",
    marginRight: 12,
  },
  headerTitle: {
    fontSize: 16,
    fontWeight: "bold",
    color: "#333",
  },
  headerSubtitle: {
    fontSize: 12,
    color: "#666",
    marginTop: 2,
  },
  closeButton: {
    padding: 8,
  },
  messagesList: {
    flex: 1,
  },
  messagesContainer: {
    padding: 16,
    paddingBottom: 8,
  },
  messageContainer: {
    flexDirection: "row",
    marginBottom: 12,
    alignItems: "flex-end",
  },
  userMessageContainer: {
    justifyContent: "flex-end",
  },
  botMessageContainer: {
    justifyContent: "flex-start",
  },
  botAvatar: {
    width: 32,
    height: 32,
    borderRadius: 16,
    backgroundColor: "#f8f9fa",
    alignItems: "center",
    justifyContent: "center",
    marginRight: 8,
  },
  messageBubble: {
    maxWidth: "80%",
    padding: 12,
    borderRadius: 18,
  },
  userMessage: {
    backgroundColor: "#FF99CC",
    alignSelf: "flex-end",
  },
  botMessage: {
    backgroundColor: "#f8f9fa",
    alignSelf: "flex-start",
  },
  messageText: {
    fontSize: 14,
    lineHeight: 20,
  },
  userMessageText: {
    color: "#fff",
  },
  botMessageText: {
    color: "#333",
  },
  timestamp: {
    fontSize: 10,
    color: "rgba(255,255,255,0.7)",
    marginTop: 4,
    alignSelf: "flex-end",
  },
  typingContainer: {
    flexDirection: "row",
    alignItems: "center",
    paddingHorizontal: 16,
    paddingBottom: 8,
  },
  typingBubble: {
    flexDirection: "row",
    alignItems: "center",
    backgroundColor: "#f8f9fa",
    padding: 12,
    borderRadius: 18,
  },
  typingText: {
    fontSize: 12,
    color: "#666",
    marginLeft: 8,
  },
  recordingContainer: {
    paddingHorizontal: 16,
    paddingBottom: 8,
    alignItems: "center",
  },
  recordingIndicator: {
    flexDirection: "row",
    alignItems: "center",
    backgroundColor: "#f44336",
    paddingHorizontal: 16,
    paddingVertical: 8,
    borderRadius: 20,
  },
  recordingDot: {
    width: 8,
    height: 8,
    borderRadius: 4,
    backgroundColor: "#fff",
    marginRight: 8,
  },
  recordingText: {
    fontSize: 12,
    color: "#fff",
    fontWeight: "500",
  },
  quickRepliesContainer: {
    paddingHorizontal: 16,
    paddingVertical: 8,
    borderTopWidth: 1,
    borderTopColor: "#eee",
  },
  quickRepliesTitle: {
    fontSize: 12,
    color: "#666",
    marginBottom: 8,
  },
  quickRepliesList: {
    paddingRight: 16,
  },
  quickReplyButton: {
    backgroundColor: "#f8f9fa",
    paddingHorizontal: 12,
    paddingVertical: 6,
    borderRadius: 15,
    marginRight: 8,
    borderWidth: 1,
    borderColor: "#e0e0e0",
  },
  quickReplyText: {
    fontSize: 12,
    color: "#333",
  },
  productsContainer: {
    marginTop: 8,
    gap: 8,
  },
  productCard: {
    flexDirection: "row",
    backgroundColor: "#f8f9fa",
    borderRadius: 12,
    padding: 12,
    borderWidth: 1,
    borderColor: "#e0e0e0",
    alignItems: "center",
    marginBottom: 10,
    shadowColor: "#000",
    shadowOffset: {
      width: 0,
      height: 1,
    },
    shadowOpacity: 0.1,
    shadowRadius: 2,
    elevation: 2,
  },
  productImageContainer: {
    marginRight: 12,
  },
  productImage: {
    width: 60,
    height: 60,
    borderRadius: 8,
    backgroundColor: "#fff",
  },
  productInfo: {
    flex: 1,
  },
  productName: {
    fontSize: 14,
    fontWeight: "600",
    color: "#333",
    marginBottom: 4,
  },
  productReason: {
    fontSize: 11,
    color: "#666",
    fontStyle: "italic",
  },
  productAction: {
    marginLeft: 8,
  },
  inputContainer: {
    flexDirection: "row",
    alignItems: "flex-end",
    padding: 16,
    borderTopWidth: 1,
    borderTopColor: "#eee",
    backgroundColor: "#fff",
  },
  textInput: {
    flex: 1,
    borderWidth: 1,
    borderColor: "#e0e0e0",
    borderRadius: 20,
    paddingHorizontal: 16,
    paddingVertical: 12,
    fontSize: 14,
    maxHeight: 100,
    marginRight: 8,
  },
  voiceButton: {
    width: 40,
    height: 40,
    borderRadius: 20,
    backgroundColor: "#4CAF50",
    alignItems: "center",
    justifyContent: "center",
    marginRight: 8,
  },
  voiceButtonRecording: {
    backgroundColor: "#f44336",
  },
  voiceButtonProcessing: {
    backgroundColor: "#FF9800",
  },
  sendButton: {
    width: 40,
    height: 40,
    borderRadius: 20,
    backgroundColor: "#FF99CC",
    alignItems: "center",
    justifyContent: "center",
  },
  sendButtonDisabled: {
    backgroundColor: "#e0e0e0",
  },
});

export default ChatBot;
